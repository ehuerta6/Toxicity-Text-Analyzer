# ToxiGuard - Advanced Toxicity Detection System

A comprehensive, production-ready system for detecting toxic content in text using advanced machine learning algorithms and contextual analysis.

## ğŸš€ Features

- **Advanced ML Classification**: Multiple algorithms including SVM, Random Forest, Naive Bayes, and Logistic Regression
- **Contextual Analysis**: Embedding-based analysis with sentence transformers for better context understanding
- **Hybrid Classification**: Combines rule-based, ML, and contextual approaches for optimal accuracy
- **Ultra-Sensitive Detection**: Advanced toxicity detection with severity weighting and repetition analysis
- **Real-time API**: FastAPI backend with comprehensive endpoints
- **Modern Frontend**: React-based dashboard with real-time analysis and visualization
- **Production Ready**: Clean, modular codebase with comprehensive error handling

## ğŸ—ï¸ Architecture

```
toxiguard/
â”œâ”€â”€ backend/                 # FastAPI backend server
â”‚   â”œâ”€â”€ app/                # Core application modules
â”‚   â”‚   â”œâ”€â”€ main.py         # FastAPI application with endpoints
â”‚   â”‚   â”œâ”€â”€ models.py       # Pydantic data models
â”‚   â”‚   â”œâ”€â”€ database.py     # SQLite database for analysis history
â”‚   â”‚   â”œâ”€â”€ hybrid_classifier.py      # Main hybrid classifier
â”‚   â”‚   â”œâ”€â”€ advanced_toxicity_classifier.py  # Ultra-sensitive classifier
â”‚   â”‚   â”œâ”€â”€ contextual_classifier.py  # Contextual analysis with embeddings
â”‚   â”‚   â”œâ”€â”€ improved_classifier.py    # Rule-based classifier
â”‚   â”‚   â”œâ”€â”€ ml_classifier.py          # ML-based classifier
â”‚   â”‚   â”œâ”€â”€ ml_models.py              # ML model management
â”‚   â”‚   â”œâ”€â”€ model_trainer.py          # Model training utilities
â”‚   â”‚   â”œâ”€â”€ weight_optimizer.py       # Weight optimization system
â”‚   â”‚   â”œâ”€â”€ advanced_preprocessor.py  # Text preprocessing
â”‚   â”‚   â””â”€â”€ services.py               # Legacy services (maintained for compatibility)
â”‚   â”œâ”€â”€ ml/                 # ML utilities and configuration
â”‚   â”‚   â”œâ”€â”€ config.py       # ML configuration
â”‚   â”‚   â””â”€â”€ model_evaluator.py  # Model evaluation utilities
â”‚   â”œâ”€â”€ models/             # Trained ML models
â”‚   â”œâ”€â”€ requirements.txt    # Python dependencies
â”‚   â””â”€â”€ README.md           # Backend documentation
â”œâ”€â”€ frontend/               # React frontend application
â”‚   â”œâ”€â”€ src/                # Source code
â”‚   â”‚   â”œâ”€â”€ components/     # React components
â”‚   â”‚   â”œâ”€â”€ hooks/          # Custom React hooks
â”‚   â”‚   â”œâ”€â”€ lib/            # Utility libraries
â”‚   â”‚   â””â”€â”€ styles/         # Styling and design system
â”‚   â”œâ”€â”€ package.json        # Node.js dependencies
â”‚   â””â”€â”€ README.md           # Frontend documentation
â”œâ”€â”€ data/                   # Training and test datasets
â””â”€â”€ README.md               # This file
```

## ğŸ”§ Backend Features

### Core Classifiers

- **Hybrid Classifier**: Combines all approaches with intelligent fallback
- **Advanced Toxicity Classifier**: Ultra-sensitive detection with severity weighting
- **Contextual Classifier**: Embedding-based analysis using sentence-transformers
- **ML Classifier**: Support for multiple ML algorithms
- **Improved Classifier**: Rule-based approach with context awareness

### API Endpoints

- `POST /analyze` - Analyze text for toxicity
- `POST /batch-analyze` - Analyze multiple texts
- `GET /classifier-info` - Get classifier information
- `POST /switch-classifier` - Switch between classifiers
- `GET /history` - Get analysis history
- `GET /stats` - Get system statistics

### Advanced Features

- **Contextual Analysis**: Detects negations and context (e.g., "not stupid" vs "stupid")
- **Severity Weighting**: Different weights for different types of toxicity
- **Repetition Analysis**: Detects repeated toxic content
- **Multi-language Support**: English and Spanish text analysis
- **Real-time Processing**: Optimized for low-latency responses

## ğŸ¨ Frontend Features

### User Interface

- **Modern Design**: Clean, responsive interface with Tailwind CSS
- **Real-time Analysis**: Instant toxicity detection with visual feedback
- **Interactive Dashboard**: Comprehensive analysis results with explanations
- **Toxicity Visualization**: Color-coded text highlighting and gauge displays
- **Responsive Layout**: Works on desktop and mobile devices

### Analysis Features

- **Text Highlighting**: Toxic words are highlighted with color coding
- **Severity Breakdown**: Detailed breakdown of toxicity by category
- **Explanation System**: Clear explanations for why content was flagged
- **Category Detection**: Identifies specific types of toxicity
- **Confidence Scoring**: Shows confidence level for each analysis

## ğŸš€ Quick Start

### Backend Setup

```bash
cd backend
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
pip install -r requirements.txt
uvicorn app.main:app --reload --port 8000
```

### Frontend Setup

```bash
cd frontend
npm install
npm run dev
```

### Access Points

- **Backend API**: http://localhost:8000
- **API Documentation**: http://localhost:8000/docs
- **Frontend**: http://localhost:5173

## ğŸ“Š Model Performance

The system includes multiple pre-trained models:

- **Linear SVM**: High accuracy for general toxicity detection
- **Random Forest**: Robust performance with complex patterns
- **Naive Bayes**: Fast classification with good baseline performance
- **Logistic Regression**: Balanced accuracy and interpretability

## ğŸ” Analysis Examples

### Contextual Understanding

- **"You are stupid"** â†’ High toxicity (85%)
- **"You are not stupid"** â†’ Low toxicity (15%) - Context detected
- **"I hate you"** â†’ High toxicity (90%)
- **"I don't hate you"** â†’ Low toxicity (10%) - Negation detected

### Multi-category Detection

- **Insults**: Mild, moderate, and severe levels
- **Harassment**: Direct threats and intimidation
- **Discrimination**: Racism, sexism, homophobia
- **Spam**: Toxic promotional content

## ğŸ› ï¸ Development

### Code Quality

- **Clean Architecture**: Modular, maintainable code structure
- **Type Hints**: Full Python type annotation support
- **Error Handling**: Comprehensive error handling and logging
- **Testing**: Built-in testing utilities and examples
- **Documentation**: Detailed docstrings and comments

### Performance Optimizations

- **Caching**: Intelligent caching of model predictions
- **Async Processing**: Non-blocking API responses
- **Memory Management**: Efficient memory usage for large texts
- **Batch Processing**: Optimized for multiple text analysis

## ğŸ“ˆ Production Deployment

### Requirements

- Python 3.8+
- Node.js 18+
- 4GB+ RAM (for ML models)
- Fast storage for model files

### Environment Variables

```bash
FRONTEND_URL=http://localhost:5173
HOST=0.0.0.0
PORT=8000
DATABASE_URL=sqlite:///analysis_history.db
```

### Scaling Considerations

- **Load Balancing**: Multiple backend instances
- **Model Caching**: Shared model storage
- **Database**: Consider PostgreSQL for high-volume production
- **Monitoring**: Health checks and performance metrics

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes with proper testing
4. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ†˜ Support

For issues and questions:

1. Check the documentation
2. Review existing issues
3. Create a new issue with detailed information

---

**ToxiGuard** - Advanced toxicity detection powered by machine learning and contextual analysis.
