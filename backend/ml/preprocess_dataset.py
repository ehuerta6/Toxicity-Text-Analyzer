#!/usr/bin/env python3
"""
Script para preprocesar el dataset completo de comentarios tÃ³xicos
"""

import pandas as pd
import numpy as np
from pathlib import Path
import sys
import time

# Agregar el directorio padre al path para importar config
sys.path.append(str(Path(__file__).parent.parent))
from ml.config import DATA_DIR
from ml.preprocessor import TextPreprocessor

def load_and_preprocess_dataset():
    """Carga y preprocesa el dataset completo"""
    print("ğŸš€ CARGA Y PREPROCESAMIENTO DEL DATASET - ToxiGuard")
    print("=" * 70)
    
    # 1. Cargar dataset
    print("\nğŸ“Š PASO 1: Cargando dataset...")
    csv_path = DATA_DIR / "toxic_comments.csv"
    
    if not csv_path.exists():
        print(f"   âŒ Archivo no encontrado: {csv_path}")
        return None
    
    print(f"   ğŸ“ Archivo encontrado: {csv_path}")
    df = pd.read_csv(csv_path)
    print(f"   âœ… Dataset cargado: {df.shape[0]:,} filas Ã— {df.shape[1]} columnas")
    
    # 2. Inicializar preprocesador
    print("\nğŸ”§ PASO 2: Inicializando preprocesador...")
    try:
        preprocessor = TextPreprocessor()
        print(f"   âœ… Preprocesador inicializado")
    except Exception as e:
        print(f"   âŒ Error inicializando preprocesador: {e}")
        return None
    
    # 3. Preprocesar dataset
    print("\nğŸ”„ PASO 3: Preprocesando textos...")
    start_time = time.time()
    
    try:
        # Preprocesar la columna de texto
        df_processed = preprocessor.preprocess_dataframe(
            df, 
            text_column="Text", 
            new_column="ProcessedText"
        )
        
        processing_time = time.time() - start_time
        print(f"   âœ… Preprocesamiento completado en {processing_time:.2f} segundos")
        
    except Exception as e:
        print(f"   âŒ Error durante preprocesamiento: {e}")
        return None
    
    # 4. Mostrar resultados
    print("\nğŸ“‹ PASO 4: Analizando resultados...")
    
    # Comparar textos originales vs procesados
    print(f"\nğŸ‘€ COMPARACIÃ“N DE TEXTO ORIGINAL VS PROCESADO:")
    print("-" * 80)
    
    for i in range(min(5, len(df_processed))):
        original_text = df_processed.iloc[i]["Text"]
        processed_text = df_processed.iloc[i]["ProcessedText"]
        
        print(f"\nğŸ“ Comentario {i+1}:")
        print(f"   Original: {original_text[:100]}{'...' if len(original_text) > 100 else ''}")
        print(f"   Procesado: {processed_text[:100]}{'...' if len(processed_text) > 100 else ''}")
        
        # EstadÃ­sticas del texto
        stats = preprocessor.get_text_statistics(original_text)
        print(f"   ğŸ“Š Longitud: {stats['original_length']} â†’ {stats['processed_length']} caracteres")
        print(f"   ğŸ”¤ Tokens: {stats['token_count']} â†’ {len(processed_text.split())} palabras")
    
    # 5. EstadÃ­sticas del dataset procesado
    print(f"\nğŸ“Š ESTADÃSTICAS DEL DATASET PROCESADO:")
    print("-" * 80)
    
    # Longitudes de texto
    original_lengths = df_processed["Text"].str.len()
    processed_lengths = df_processed["ProcessedText"].str.len()
    
    print(f"   ğŸ“ Longitud de texto original:")
    print(f"      Promedio: {original_lengths.mean():.1f} caracteres")
    print(f"      MÃ­nima: {original_lengths.min()} caracteres")
    print(f"      MÃ¡xima: {original_lengths.max()} caracteres")
    
    print(f"\n   ğŸ“ Longitud de texto procesado:")
    print(f"      Promedio: {processed_lengths.mean():.1f} caracteres")
    print(f"      MÃ­nima: {processed_lengths.min()} caracteres")
    print(f"      MÃ¡xima: {processed_lengths.max()} caracteres")
    
    # ReducciÃ³n de longitud
    reduction = ((original_lengths.mean() - processed_lengths.mean()) / original_lengths.mean()) * 100
    print(f"\n   ğŸ“‰ ReducciÃ³n promedio: {reduction:.1f}%")
    
    # 6. Guardar dataset procesado
    print(f"\nğŸ’¾ PASO 5: Guardando dataset procesado...")
    
    output_path = DATA_DIR / "toxic_comments_processed.csv"
    try:
        df_processed.to_csv(output_path, index=False)
        print(f"   âœ… Dataset guardado en: {output_path}")
        print(f"   ğŸ“ TamaÃ±o del archivo: {output_path.stat().st_size / 1024:.1f} KB")
    except Exception as e:
        print(f"   âŒ Error guardando archivo: {e}")
    
    # 7. Resumen final
    print(f"\nğŸ‰ RESUMEN FINAL:")
    print("-" * 80)
    print(f"   ğŸ“Š Dataset original: {df.shape[0]:,} filas Ã— {df.shape[1]} columnas")
    print(f"   ğŸ“Š Dataset procesado: {df_processed.shape[0]:,} filas Ã— {df_processed.shape[1]} columnas")
    print(f"   â±ï¸  Tiempo de procesamiento: {processing_time:.2f} segundos")
    print(f"   ğŸ“‰ ReducciÃ³n de texto: {reduction:.1f}%")
    print(f"   ğŸ’¾ Archivo guardado: {output_path.name}")
    
    return df_processed

def analyze_toxicity_distribution(df):
    """Analiza la distribuciÃ³n de toxicidad en el dataset"""
    if df is None:
        return
    
    print(f"\nğŸ” ANÃLISIS DE DISTRIBUCIÃ“N DE TOXICIDAD:")
    print("-" * 80)
    
    # Columnas de etiquetas (excluyendo las de texto)
    label_columns = [col for col in df.columns if col.startswith("Is") and col not in ["IsToxic"]]
    
    print(f"   ğŸ·ï¸  Etiquetas disponibles: {len(label_columns)}")
    
    # DistribuciÃ³n de la etiqueta principal
    if "IsToxic" in df.columns:
        toxic_dist = df["IsToxic"].value_counts()
        total = len(df)
        print(f"\n   ğŸ¯ DistribuciÃ³n de IsToxic:")
        for value, count in toxic_dist.items():
            percentage = (count / total) * 100
            print(f"      {value}: {count:,} ({percentage:.1f}%)")
    
    # DistribuciÃ³n de otras etiquetas
    print(f"\n   ğŸ“Š DistribuciÃ³n de otras etiquetas:")
    for col in label_columns[:5]:  # Solo las primeras 5 para no saturar
        if col in df.columns:
            dist = df[col].value_counts()
            total = len(df)
            print(f"\n      {col}:")
            for value, count in dist.items():
                percentage = (count / total) * 100
                print(f"         {value}: {count:,} ({percentage:.1f}%)")

def main():
    """FunciÃ³n principal"""
    print("ğŸš€ PREPROCESAMIENTO COMPLETO DEL DATASET - ToxiGuard")
    print("=" * 80)
    
    try:
        # Cargar y preprocesar dataset
        df_processed = load_and_preprocess_dataset()
        
        if df_processed is not None:
            # Analizar distribuciÃ³n de toxicidad
            analyze_toxicity_distribution(df_processed)
            
            print(f"\nğŸ‰ Â¡Proceso completado exitosamente!")
            print(f"   El dataset estÃ¡ listo para vectorizaciÃ³n y entrenamiento")
        else:
            print(f"\nâŒ No se pudo completar el proceso")
            
    except Exception as e:
        print(f"\nâŒ Error durante el proceso: {e}")
        import traceback
        traceback.print_exc()
    
    print("\n" + "=" * 80)

if __name__ == "__main__":
    main()
