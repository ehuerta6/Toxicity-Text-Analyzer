#!/usr/bin/env python3
"""
Script para probar las funciones de preprocesamiento con ejemplos del dataset real
"""

import pandas as pd
from pathlib import Path
import sys

# Agregar el directorio padre al path para importar config
sys.path.append(str(Path(__file__).parent.parent))
from ml.config import DATA_DIR
from ml.preprocess import clean_text, tokenize_and_lemmatize, preprocess_text, preprocess_batch

def test_with_dataset_examples():
    """
    Prueba las funciones de preprocesamiento con ejemplos reales del dataset
    """
    print("üß™ PRUEBA CON EJEMPLOS DEL DATASET REAL - ToxiGuard")
    print("=" * 70)
    
    # Cargar dataset
    csv_path = DATA_DIR / "toxic_comments.csv"
    
    if not csv_path.exists():
        print(f"‚ùå Dataset no encontrado: {csv_path}")
        return
    
    print(f"üìä Cargando dataset: {csv_path}")
    df = pd.read_csv(csv_path)
    print(f"‚úÖ Dataset cargado: {df.shape[0]:,} filas √ó {df.shape[1]} columnas")
    
    # Seleccionar ejemplos variados del dataset
    print(f"\nüîç Seleccionando ejemplos del dataset...")
    
    # Ejemplo t√≥xico
    toxic_example = df[df['IsToxic'] == True]['Text'].iloc[0]
    print(f"   üìù Ejemplo t√≥xico: {toxic_example[:100]}{'...' if len(toxic_example) > 100 else ''}")
    
    # Ejemplo no t√≥xico
    non_toxic_example = df[df['IsToxic'] == False]['Text'].iloc[0]
    print(f"   üìù Ejemplo no t√≥xico: {non_toxic_example[:100]}{'...' if len(non_toxic_example) > 100 else ''}")
    
    # Ejemplo largo
    long_example = df.loc[df['Text'].str.len().idxmax(), 'Text']
    print(f"   üìù Ejemplo largo: {long_example[:100]}{'...' if len(long_example) > 100 else ''}")
    
    # Ejemplo corto
    short_example = df.loc[df['Text'].str.len().idxmin(), 'Text']
    print(f"   üìù Ejemplo corto: {short_example}")
    
    # Ejemplo con URLs/emails
    url_email_example = df[df['Text'].str.contains('http|@', na=False)]['Text'].iloc[0]
    print(f"   üìù Ejemplo con URLs/emails: {url_email_example[:100]}{'...' if len(url_email_example) > 100 else ''}")
    
    # Lista de ejemplos para probar
    examples = [
        ("T√≥xico", toxic_example),
        ("No t√≥xico", non_toxic_example),
        ("Largo", long_example),
        ("Corto", short_example),
        ("Con URLs/emails", url_email_example)
    ]
    
    print(f"\nüîß PROBANDO FUNCI√ìN clean_text() CON EJEMPLOS DEL DATASET:")
    print("=" * 80)
    
    for category, text in examples:
        print(f"\nüìù {category}:")
        print(f"   Original: {text[:150]}{'...' if len(text) > 150 else ''}")
        
        cleaned = clean_text(text)
        print(f"   Limpio: {cleaned[:150]}{'...' if len(cleaned) > 150 else ''}")
        
        reduction = ((len(text) - len(cleaned)) / len(text) * 100) if len(text) > 0 else 0
        print(f"   Reducci√≥n: {reduction:.1f}% ({len(text)} ‚Üí {len(cleaned)} caracteres)")
    
    print(f"\nüî§ PROBANDO FUNCI√ìN tokenize_and_lemmatize() CON EJEMPLOS DEL DATASET:")
    print("=" * 80)
    
    for category, text in examples:
        print(f"\nüìù {category}:")
        print(f"   Original: {text[:100]}{'...' if len(text) > 100 else ''}")
        
        tokens = tokenize_and_lemmatize(text)
        print(f"   Tokens: {tokens[:20]}{'...' if len(tokens) > 20 else ''}")
        print(f"   Cantidad: {len(tokens)} tokens")
        
        # Mostrar algunos tokens espec√≠ficos
        if tokens:
            print(f"   Primeros 5: {tokens[:5]}")
            print(f"   √öltimos 5: {tokens[-5:] if len(tokens) > 5 else tokens}")
    
    print(f"\nüöÄ PROBANDO FUNCI√ìN preprocess_text() CON EJEMPLOS DEL DATASET:")
    print("=" * 80)
    
    for category, text in examples:
        print(f"\nüìù {category}:")
        print(f"   Original: {text[:100]}{'...' if len(text) > 100 else ''}")
        
        processed = preprocess_text(text)
        print(f"   Procesado: {processed[:100]}{'...' if len(processed) > 100 else ''}")
        
        reduction = ((len(text) - len(processed)) / len(text) * 100) if len(text) > 0 else 0
        print(f"   Reducci√≥n: {reduction:.1f}% ({len(text)} ‚Üí {len(processed)} caracteres)")
    
    print(f"\nüì¶ PROBANDO FUNCI√ìN preprocess_batch() CON EJEMPLOS DEL DATASET:")
    print("=" * 80)
    
    # Extraer solo los textos de los ejemplos
    example_texts = [text for _, text in examples]
    
    try:
        processed_batch = preprocess_batch(example_texts)
        print(f"‚úÖ Batch procesado exitosamente")
        
        # Mostrar comparaci√≥n
        print(f"\nüìä COMPARACI√ìN FINAL:")
        print("-" * 80)
        
        total_original = sum(len(text) for text in example_texts)
        total_processed = sum(len(text) for text in processed_batch)
        reduction = ((total_original - total_processed) / total_original) * 100 if total_original > 0 else 0
        
        print(f"   üìè Caracteres totales:")
        print(f"      Original: {total_original:,}")
        print(f"      Procesado: {total_processed:,}")
        print(f"      Reducci√≥n: {reduction:.1f}%")
        
        # Mostrar ejemplos espec√≠ficos
        for i, (category, original_text) in enumerate(examples):
            processed_text = processed_batch[i]
            print(f"\n   {category}:")
            print(f"      Original: {original_text[:80]}{'...' if len(original_text) > 80 else ''}")
            print(f"      Procesado: {processed_text[:80]}{'...' if len(processed_text) > 80 else ''}")
            
    except Exception as e:
        print(f"‚ùå Error en batch processing: {e}")
    
    print(f"\n‚úÖ Prueba con ejemplos del dataset completada")

def analyze_preprocessing_quality():
    """
    Analiza la calidad del preprocesamiento con estad√≠sticas del dataset
    """
    print(f"\nüìä AN√ÅLISIS DE CALIDAD DEL PREPROCESAMIENTO")
    print("=" * 70)
    
    # Cargar dataset
    csv_path = DATA_DIR / "toxic_comments.csv"
    df = pd.read_csv(csv_path)
    
    # Estad√≠sticas del dataset original
    print(f"üìã ESTAD√çSTICAS DEL DATASET ORIGINAL:")
    print(f"   Total de comentarios: {len(df):,}")
    print(f"   Longitud promedio: {df['Text'].str.len().mean():.1f} caracteres")
    print(f"   Longitud m√≠nima: {df['Text'].str.len().min()} caracteres")
    print(f"   Longitud m√°xima: {df['Text'].str.len().max()} caracteres")
    
    # Comentarios con URLs
    urls_count = df['Text'].str.contains('http', na=False).sum()
    print(f"   Comentarios con URLs: {urls_count:,} ({urls_count/len(df)*100:.1f}%)")
    
    # Comentarios con emails
    emails_count = df['Text'].str.contains('@', na=False).sum()
    print(f"   Comentarios con emails: {emails_count:,} ({emails_count/len(df)*100:.1f}%)")
    
    # Comentarios con n√∫meros
    numbers_count = df['Text'].str.contains(r'\d', na=False).sum()
    print(f"   Comentarios con n√∫meros: {numbers_count:,} ({numbers_count/len(df)*100:.1f}%)")
    
    # Comentarios con puntuaci√≥n excesiva
    excessive_punct = df['Text'].str.contains(r'[!]{2,}|[?]{2,}', na=False).sum()
    print(f"   Comentarios con puntuaci√≥n excesiva: {excessive_punct:,} ({excessive_punct/len(df)*100:.1f}%)")
    
    print(f"\nüéØ BENEFICIOS DEL PREPROCESAMIENTO:")
    print(f"   ‚úÖ Eliminaci√≥n de URLs y emails innecesarios")
    print(f"   ‚úÖ Normalizaci√≥n de texto (min√∫sculas)")
    print(f"   ‚úÖ Eliminaci√≥n de puntuaci√≥n excesiva")
    print(f"   ‚úÖ Lematizaci√≥n para mejor comprensi√≥n")
    print(f"   ‚úÖ Filtrado de stop words")
    print(f"   ‚úÖ Preparaci√≥n para vectorizaci√≥n TF-IDF")

def main():
    """Funci√≥n principal"""
    print("üöÄ PRUEBA DE PREPROCESAMIENTO CON DATASET REAL - ToxiGuard")
    print("=" * 80)
    
    try:
        # Probar con ejemplos del dataset
        test_with_dataset_examples()
        
        # Analizar calidad del preprocesamiento
        analyze_preprocessing_quality()
        
        print(f"\nüéâ ¬°Pruebas completadas exitosamente!")
        print(f"   Las funciones de preprocesamiento est√°n listas para el pipeline de ML")
        
    except Exception as e:
        print(f"\n‚ùå Error durante las pruebas: {e}")
        import traceback
        traceback.print_exc()
    
    print("\n" + "=" * 80)

if __name__ == "__main__":
    main()
