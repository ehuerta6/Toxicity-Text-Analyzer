#!/usr/bin/env python3
"""
ğŸ§ª Test Backend Consolidado - ToxiGuard
Script unificado para probar todas las funcionalidades del backend
"""

import requests
import time
import json
from typing import Dict, Any

# ConfiguraciÃ³n
BACKEND_URL = "http://127.0.0.1:8000"
TEST_TEXTS = [
    # Textos seguros
    "Hola, Â¿cÃ³mo estÃ¡s?",
    "Me encanta esta aplicaciÃ³n",
    "Gracias por tu ayuda",
    "Excelente trabajo",
    "Muy interesante",
    
    # Textos tÃ³xicos leves
    "Eres un poco tonto",
    "No me gusta esto",
    "Esto es malo",
    
    # Textos tÃ³xicos moderados
    "Eres un idiota",
    "Vete al diablo",
    "Esto es una mierda",
    
    # Textos tÃ³xicos severos
    "Eres un idiota estÃºpido",
    "Vete al diablo, imbÃ©cil",
    "Fuck you, asshole",
    "Go to hell, you stupid moron"
]

def test_backend_health():
    """Prueba la salud del backend"""
    print("ğŸ”Œ Verificando salud del backend...")
    
    try:
        response = requests.get(f"{BACKEND_URL}/health", timeout=5)
        if response.status_code == 200:
            data = response.json()
            print(f"âœ… Backend saludable")
            print(f"   Estado: {data.get('status')}")
            print(f"   Modelo: {data.get('model_status')}")
            print(f"   Uptime: {data.get('uptime', 0):.2f}s")
            return True
        else:
            print(f"âŒ Backend no saludable: {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ Error conectando al backend: {e}")
        return False

def test_model_status():
    """Prueba el estado del modelo ML"""
    print("\nğŸ¤– Verificando estado del modelo ML...")
    
    try:
        response = requests.get(f"{BACKEND_URL}/ml/status", timeout=5)
        if response.status_code == 200:
            data = response.json()
            print(f"âœ… Estado del modelo:")
            print(f"   Cargado: {data.get('model_loaded')}")
            print(f"   Modelo disponible: {data.get('ml_model_available')}")
            print(f"   Vectorizador disponible: {data.get('vectorizer_available')}")
            print(f"   Estado: {data.get('status')}")
            return data.get('model_loaded', False)
        else:
            print(f"âŒ Error obteniendo estado: {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ Error: {e}")
        return False

def test_toxicity_analysis(text: str, expected_toxic: bool = None) -> Dict[str, Any]:
    """Prueba el anÃ¡lisis de toxicidad de un texto"""
    try:
        start_time = time.time()
        
        response = requests.post(
            f"{BACKEND_URL}/analyze",
            json={"text": text},
            timeout=10
        )
        
        response_time = time.time() - start_time
        
        if response.status_code == 200:
            result = response.json()
            
            # Verificar que los resultados varÃ­en
            toxic = result.get('toxic', False)
            score = result.get('score', 0.0)
            percentage = result.get('toxicity_percentage', 0.0)
            model_used = result.get('model_used', 'Unknown')
            
            print(f"   ğŸ“ '{text[:30]}...'")
            print(f"      TÃ³xico: {toxic} | Score: {score:.3f} | {percentage}%")
            print(f"      Modelo: {model_used} | Tiempo: {response_time:.3f}s")
            
            # Verificar expectativa si se proporciona
            if expected_toxic is not None:
                if toxic == expected_toxic:
                    print(f"      âœ… Resultado esperado")
                else:
                    print(f"      âŒ Resultado inesperado (esperado: {expected_toxic})")
            
            return result
        else:
            print(f"   âŒ Error HTTP: {response.status_code}")
            print(f"      {response.text}")
            return {}
            
    except Exception as e:
        print(f"   âŒ Error: {e}")
        return {}

def test_multiple_texts():
    """Prueba mÃºltiples textos para verificar variabilidad"""
    print("\nğŸ§ª Probando anÃ¡lisis de mÃºltiples textos...")
    
    results = []
    
    for i, text in enumerate(TEST_TEXTS, 1):
        print(f"\nğŸ“ Texto {i}/{len(TEST_TEXTS)}:")
        
        # Determinar expectativa basada en el contenido
        expected_toxic = any(word in text.lower() for word in [
            'idiota', 'tonto', 'diablo', 'mierda', 'fuck', 'asshole', 'hell', 'stupid', 'moron'
        ])
        
        result = test_toxicity_analysis(text, expected_toxic)
        if result:
            results.append(result)
        
        # Pausa breve entre requests
        time.sleep(0.5)
    
    return results

def test_history_endpoints():
    """Prueba los endpoints de historial"""
    print("\nğŸ“š Probando endpoints de historial...")
    
    # Probar obtener historial
    try:
        response = requests.get(f"{BACKEND_URL}/history", timeout=5)
        if response.status_code == 200:
            data = response.json()
            print(f"   âœ… Historial obtenido: {data.get('total', 0)} elementos")
        else:
            print(f"   âŒ Error obteniendo historial: {response.status_code}")
    except Exception as e:
        print(f"   âŒ Error: {e}")
    
    # Probar estadÃ­sticas
    try:
        response = requests.get(f"{BACKEND_URL}/history/stats", timeout=5)
        if response.status_code == 200:
            data = response.json()
            print(f"   âœ… EstadÃ­sticas obtenidas: {data.get('total_analyses', 0)} anÃ¡lisis totales")
        else:
            print(f"   âŒ Error obteniendo estadÃ­sticas: {response.status_code}")
    except Exception as e:
        print(f"   âŒ Error: {e}")

def test_keywords_endpoints():
    """Prueba los endpoints de palabras clave"""
    print("\nğŸ”‘ Probando endpoints de palabras clave...")
    
    # Probar obtener palabras clave
    try:
        response = requests.get(f"{BACKEND_URL}/keywords", timeout=5)
        if response.status_code == 200:
            data = response.json()
            print(f"   âœ… Palabras clave obtenidas: {data.get('count', 0)} palabras")
        else:
            print(f"   âŒ Error obteniendo palabras clave: {response.status_code}")
    except Exception as e:
        print(f"   âŒ Error: {e}")
    
    # Probar obtener categorÃ­as
    try:
        response = requests.get(f"{BACKEND_URL}/categories", timeout=5)
        if response.status_code == 200:
            data = response.json()
            print(f"   âœ… CategorÃ­as obtenidas: {data.get('total_categories', 0)} categorÃ­as")
        else:
            print(f"   âŒ Error obteniendo categorÃ­as: {response.status_code}")
    except Exception as e:
        print(f"   âŒ Error: {e}")

def analyze_results_variability(results: list):
    """Analiza la variabilidad de los resultados"""
    print("\nğŸ“Š ANÃLISIS DE VARIABILIDAD")
    print("=" * 50)
    
    if not results:
        print("âŒ No hay resultados para analizar")
        return
    
    # EstadÃ­sticas bÃ¡sicas
    total = len(results)
    toxic_count = sum(1 for r in results if r.get('toxic', False))
    safe_count = total - toxic_count
    
    print(f"ğŸ“ˆ Total de anÃ¡lisis: {total}")
    print(f"ğŸš¨ TÃ³xicos detectados: {toxic_count}")
    print(f"âœ… Seguros detectados: {safe_count}")
    print(f"ğŸ“Š Porcentaje tÃ³xico: {(toxic_count/total)*100:.1f}%")
    
    # Verificar variabilidad en scores
    scores = [r.get('score', 0.0) for r in results]
    unique_scores = len(set(scores))
    
    print(f"\nğŸ¯ Variabilidad de scores:")
    print(f"   Scores Ãºnicos: {unique_scores}/{total}")
    print(f"   Score mÃ­nimo: {min(scores):.3f}")
    print(f"   Score mÃ¡ximo: {max(scores):.3f}")
    print(f"   Score promedio: {sum(scores)/len(scores):.3f}")
    
    # Verificar modelos utilizados
    models_used = set(r.get('model_used', 'Unknown') for r in results)
    print(f"\nğŸ¤– Modelos utilizados: {', '.join(models_used)}")
    
    # Verificar tiempos de respuesta
    response_times = [r.get('response_time_ms', 0) for r in results]
    avg_time = sum(response_times) / len(response_times)
    max_time = max(response_times)
    
    print(f"\nâ±ï¸  Tiempos de respuesta:")
    print(f"   Promedio: {avg_time:.1f}ms")
    print(f"   MÃ¡ximo: {max_time:.1f}ms")
    
    # Verificar que no hay resultados duplicados
    unique_results = len(set(json.dumps(r, sort_keys=True) for r in results))
    if unique_results == total:
        print(f"\nâœ… Todos los resultados son Ãºnicos")
    else:
        print(f"\nâš ï¸  Algunos resultados estÃ¡n duplicados")
        print(f"   Ãšnicos: {unique_results}/{total}")

def test_error_handling():
    """Prueba el manejo de errores"""
    print("\nğŸš¨ Probando manejo de errores...")
    
    # Texto vacÃ­o
    print("   ğŸ“ Probando texto vacÃ­o...")
    try:
        response = requests.post(
            f"{BACKEND_URL}/analyze",
            json={"text": ""},
            timeout=5
        )
        if response.status_code == 400:
            print("      âœ… Error manejado correctamente")
        else:
            print(f"      âŒ CÃ³digo inesperado: {response.status_code}")
    except Exception as e:
        print(f"      âŒ Error: {e}")
    
    # Texto muy largo
    print("   ğŸ“ Probando texto muy largo...")
    long_text = "a" * 15000
    try:
        response = requests.post(
            f"{BACKEND_URL}/analyze",
            json={"text": long_text},
            timeout=5
        )
        if response.status_code == 400:
            print("      âœ… Error manejado correctamente")
        else:
            print(f"      âŒ CÃ³digo inesperado: {response.status_code}")
    except Exception as e:
        print(f"      âŒ Error: {e}")

def main():
    """FunciÃ³n principal"""
    print("ğŸš€ TOXIGUARD - PRUEBA DEL BACKEND REFACTORIZADO")
    print("=" * 60)
    print(f"â° Fecha: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸŒ Backend URL: {BACKEND_URL}")
    print()
    
    # Verificar conectividad
    if not test_backend_health():
        print("\nâŒ Backend no disponible")
        print("ğŸ”§ AsegÃºrese de que el backend estÃ© ejecutÃ¡ndose:")
        print("   cd backend && python start_optimized.py --env development")
        return
    
    # Verificar estado del modelo
    model_loaded = test_model_status()
    
    # Probar anÃ¡lisis de toxicidad
    results = test_multiple_texts()
    
    # Probar endpoints adicionales
    test_history_endpoints()
    test_keywords_endpoints()
    
    # Analizar resultados
    analyze_results_variability(results)
    
    # Probar manejo de errores
    test_error_handling()
    
    print("\n" + "=" * 60)
    print("âœ… PRUEBAS COMPLETADAS")
    
    if model_loaded:
        print("ğŸ¤– Modelo ML funcionando correctamente")
    else:
        print("âš ï¸  Usando clasificador mejorado (fallback)")
    
    print("\nğŸ“Š RESUMEN:")
    print("   - Backend refactorizado y funcionando")
    print("   - AnÃ¡lisis de toxicidad variando correctamente")
    print("   - Endpoints de historial y palabras clave funcionando")
    print("   - Manejo de errores implementado")
    print("   - Tiempos de respuesta optimizados")

if __name__ == "__main__":
    main()
