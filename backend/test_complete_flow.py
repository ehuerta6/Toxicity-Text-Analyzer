#!/usr/bin/env python3
"""
Script para probar el flujo completo del sistema ToxiGuard con modelo ML
"""

import requests
import json
import time
from pathlib import Path
import sys

# Agregar el directorio padre al path
sys.path.append(str(Path(__file__).parent.parent))

def test_backend_health():
    """Prueba la salud del backend"""
    print("üè• PROBANDO SALUD DEL BACKEND")
    print("=" * 50)
    
    try:
        # Probar endpoint de salud
        response = requests.get("http://localhost:8000/health")
        if response.status_code == 200:
            print("   ‚úÖ Endpoint /health: FUNCIONANDO")
        else:
            print(f"   ‚ùå Endpoint /health: Error {response.status_code}")
            return False
        
        # Probar endpoint de API health
        response = requests.get("http://localhost:8000/api/health")
        if response.status_code == 200:
            print("   ‚úÖ Endpoint /api/health: FUNCIONANDO")
        else:
            print(f"   ‚ùå Endpoint /api/health: Error {response.status_code}")
            return False
        
        return True
        
    except requests.exceptions.ConnectionError:
        print("   ‚ùå No se puede conectar al backend. ¬øEst√° ejecut√°ndose?")
        return False
    except Exception as e:
        print(f"   ‚ùå Error probando salud del backend: {e}")
        return False

def test_ml_model_status():
    """Prueba el estado del modelo ML"""
    print("\nü§ñ PROBANDO ESTADO DEL MODELO ML")
    print("=" * 50)
    
    try:
        response = requests.get("http://localhost:8000/ml/status")
        if response.status_code == 200:
            status_data = response.json()
            print(f"   üìä Estado del modelo: {status_data['status']}")
            print(f"   üì• Modelo cargado: {status_data['model_loaded']}")
            print(f"   üîß Modelo disponible: {status_data['ml_model_available']}")
            print(f"   üìä Vectorizador disponible: {status_data['vectorizer_available']}")
            print(f"   üí¨ Mensaje: {status_data['message']}")
            
            if status_data['model_loaded']:
                print("   ‚úÖ Modelo ML listo para usar")
                return True
            else:
                print("   ‚ö†Ô∏è  Modelo ML no est√° cargado")
                return False
        else:
            print(f"   ‚ùå Error obteniendo estado del modelo: {response.status_code}")
            return False
            
    except Exception as e:
        print(f"   ‚ùå Error probando estado del modelo ML: {e}")
        return False

def test_ml_model_predictions():
    """Prueba predicciones del modelo ML"""
    print("\nüß™ PROBANDO PREDICCIONES DEL MODELO ML")
    print("=" * 50)
    
    test_cases = [
        {
            "text": "Hello world! This is a nice comment about the weather.",
            "expected": "safe",
            "description": "Comentario positivo"
        },
        {
            "text": "You are an idiot and I hate you!",
            "expected": "toxic",
            "description": "Comentario t√≥xico directo"
        },
        {
            "text": "This is a neutral comment about technology.",
            "expected": "safe",
            "description": "Comentario neutral"
        },
        {
            "text": "Go to hell you stupid person!",
            "expected": "toxic",
            "description": "Comentario t√≥xico agresivo"
        },
        {
            "text": "Thank you for your help, it was very useful.",
            "expected": "safe",
            "description": "Comentario agradecido"
        },
        {
            "text": "I can't believe how dumb this is.",
            "expected": "toxic",
            "description": "Comentario t√≥xico sutil"
        }
    ]
    
    results = []
    
    for i, test_case in enumerate(test_cases, 1):
        try:
            print(f"\n   üìù Caso {i}: {test_case['description']}")
            print(f"      Texto: {test_case['text'][:60]}{'...' if len(test_case['text']) > 60 else ''}")
            
            # Probar endpoint de prueba ML
            response = requests.post(
                "http://localhost:8000/ml/test",
                data={"text": test_case['text']}
            )
            
            if response.status_code == 200:
                result = response.json()
                prediction = result['prediction_class']
                confidence = result['confidence']
                
                print(f"      Predicci√≥n: {prediction.upper()}")
                print(f"      Confianza: {confidence:.3f}")
                print(f"      Texto procesado: {result['processed_text'][:50]}{'...' if len(result['processed_text']) > 50 else ''}")
                
                # Verificar si la predicci√≥n es correcta
                is_correct = (prediction == test_case['expected'])
                status = "‚úÖ CORRECTO" if is_correct else "‚ùå INCORRECTO"
                print(f"      Resultado: {status}")
                
                results.append({
                    'case': i,
                    'text': test_case['text'],
                    'expected': test_case['expected'],
                    'predicted': prediction,
                    'confidence': confidence,
                    'correct': is_correct
                })
                
            else:
                print(f"      ‚ùå Error en predicci√≥n: {response.status_code}")
                results.append({
                    'case': i,
                    'text': test_case['text'],
                    'expected': test_case['expected'],
                    'predicted': 'error',
                    'confidence': 0.0,
                    'correct': False
                })
                
        except Exception as e:
            print(f"      ‚ùå Error en caso {i}: {e}")
            results.append({
                'case': i,
                'text': test_case['text'],
                'expected': test_case['expected'],
                'predicted': 'error',
                'confidence': 0.0,
                'correct': False
            })
    
    # Resumen de resultados
    correct_predictions = sum(1 for r in results if r['correct'])
    total_predictions = len(results)
    accuracy = (correct_predictions / total_predictions) * 100 if total_predictions > 0 else 0
    
    print(f"\n   üìä RESUMEN DE PREDICCIONES:")
    print(f"      Correctas: {correct_predictions}/{total_predictions}")
    print(f"      Precisi√≥n: {accuracy:.1f}%")
    
    return results

def test_analyze_endpoint():
    """Prueba el endpoint principal /analyze"""
    print("\nüîç PROBANDO ENDPOINT PRINCIPAL /ANALYZE")
    print("=" * 50)
    
    test_cases = [
        {
            "text": "This is a wonderful day!",
            "description": "Texto positivo"
        },
        {
            "text": "You are so stupid and annoying!",
            "description": "Texto t√≥xico"
        },
        {
            "text": "The weather is nice today.",
            "description": "Texto neutral"
        }
    ]
    
    results = []
    
    for i, test_case in enumerate(test_cases, 1):
        try:
            print(f"\n   üìù Caso {i}: {test_case['description']}")
            print(f"      Texto: {test_case['text'][:50]}{'...' if len(test_case['text']) > 50 else ''}")
            
            # Medir tiempo de respuesta
            start_time = time.time()
            
            response = requests.post(
                "http://localhost:8000/analyze",
                json={"text": test_case['text']}
            )
            
            response_time = time.time() - start_time
            
            if response.status_code == 200:
                result = response.json()
                
                print(f"      T√≥xico: {'S√ç' if result['toxic'] else 'NO'}")
                print(f"      Score: {result['score']:.3f}")
                print(f"      Etiquetas: {result['labels']}")
                print(f"      Longitud: {result['text_length']} caracteres")
                print(f"      Palabras clave: {result['keywords_found']}")
                print(f"      Tiempo respuesta: {response_time:.3f}s")
                
                results.append({
                    'case': i,
                    'text': test_case['text'],
                    'toxic': result['toxic'],
                    'score': result['score'],
                    'labels': result['labels'],
                    'response_time': response_time,
                    'success': True
                })
                
            else:
                print(f"      ‚ùå Error: {response.status_code}")
                results.append({
                    'case': i,
                    'text': test_case['text'],
                    'success': False
                })
                
        except Exception as e:
            print(f"      ‚ùå Error en caso {i}: {e}")
            results.append({
                'case': i,
                'text': test_case['text'],
                'success': False
            })
    
    return results

def test_performance():
    """Prueba el rendimiento del sistema"""
    print("\n‚ö° PROBANDO RENDIMIENTO")
    print("=" * 50)
    
    # Texto largo para probar rendimiento
    long_text = "This is a very long comment that contains many words and sentences. " * 50
    
    print(f"   üìè Texto de prueba: {len(long_text)} caracteres")
    
    try:
        # Medir tiempo de respuesta
        start_time = time.time()
        
        response = requests.post(
            "http://localhost:8000/analyze",
            json={"text": long_text}
        )
        
        response_time = time.time() - start_time
        
        if response.status_code == 200:
            result = response.json()
            print(f"   ‚úÖ An√°lisis exitoso")
            print(f"   ‚è±Ô∏è  Tiempo de respuesta: {response_time:.3f} segundos")
            print(f"   üìä Resultado: {'T√≥xico' if result['toxic'] else 'No T√≥xico'}")
            print(f"   üéØ Score: {result['score']:.3f}")
            
            # Evaluar rendimiento
            if response_time < 1.0:
                print("   üöÄ Rendimiento: EXCELENTE (< 1s)")
            elif response_time < 2.0:
                print("   ‚úÖ Rendimiento: BUENO (< 2s)")
            elif response_time < 5.0:
                print("   ‚ö†Ô∏è  Rendimiento: ACEPTABLE (< 5s)")
            else:
                print("   ‚ùå Rendimiento: LENTO (> 5s)")
                
            return response_time
            
        else:
            print(f"   ‚ùå Error en an√°lisis: {response.status_code}")
            return None
            
    except Exception as e:
        print(f"   ‚ùå Error probando rendimiento: {e}")
        return None

def compare_with_naive_classifier():
    """Compara resultados del modelo ML vs clasificador na√Øve"""
    print("\nüîÑ COMPARANDO MODELO ML vs CLASIFICADOR NA√èVE")
    print("=" * 50)
    
    test_texts = [
        "You are an idiot!",
        "This is a nice comment.",
        "Go to hell you stupid person!",
        "Thank you for your help."
    ]
    
    print("   üìù Textos de prueba:")
    for i, text in enumerate(test_texts, 1):
        print(f"      {i}. {text}")
    
    print("\n   ü§ñ Resultados del modelo ML:")
    
    ml_results = []
    for text in test_texts:
        try:
            response = requests.post(
                "http://localhost:8000/ml/test",
                data={"text": text}
            )
            
            if response.status_code == 200:
                result = response.json()
                ml_results.append({
                    'text': text,
                    'prediction': result['prediction_class'],
                    'confidence': result['confidence']
                })
                print(f"      '{text[:30]}{'...' if len(text) > 30 else ''}' ‚Üí {result['prediction_class'].upper()} (conf: {result['confidence']:.3f})")
            else:
                print(f"      '{text[:30]}{'...' if len(text) > 30 else ''}' ‚Üí ERROR")
                
        except Exception as e:
            print(f"      '{text[:30]}{'...' if len(text) > 30 else ''}' ‚Üí ERROR: {e}")
    
    print("\n   üìä An√°lisis de resultados:")
    toxic_count = sum(1 for r in ml_results if r['prediction'] == 'toxic')
    safe_count = sum(1 for r in ml_results if r['prediction'] == 'safe')
    
    print(f"      T√≥xicos detectados: {toxic_count}")
    print(f"      Seguros detectados: {safe_count}")
    print(f"      Total analizados: {len(ml_results)}")

def main():
    """Funci√≥n principal"""
    print("üöÄ PRUEBAS COMPLETAS DEL FLUJO INTEGRAL - ToxiGuard")
    print("=" * 80)
    
    print("\n‚ö†Ô∏è  IMPORTANTE: Aseg√∫rate de que el backend est√© ejecut√°ndose en http://localhost:8000")
    print("   Comando: uvicorn app.main:app --reload --port 8000 --host 0.0.0.0")
    
    input("\nPresiona Enter cuando el backend est√© ejecut√°ndose...")
    
    tests = [
        ("Salud del Backend", test_backend_health),
        ("Estado del Modelo ML", test_ml_model_status),
        ("Predicciones del Modelo ML", test_ml_model_predictions),
        ("Endpoint Principal /analyze", test_analyze_endpoint),
        ("Rendimiento", test_performance),
        ("Comparaci√≥n ML vs Na√Øve", compare_with_naive_classifier)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        print(f"\n{'='*20} {test_name} {'='*20}")
        try:
            result = test_func()
            results.append((test_name, True, result))
        except Exception as e:
            print(f"‚ùå Error en {test_name}: {e}")
            results.append((test_name, False, None))
    
    # Resumen final
    print(f"\n{'='*80}")
    print("üìä RESUMEN FINAL DE PRUEBAS")
    print("=" * 80)
    
    passed = 0
    total = len(results)
    
    for test_name, success, result in results:
        status = "‚úÖ PAS√ì" if success else "‚ùå FALL√ì"
        print(f"   {test_name}: {status}")
        if success:
            passed += 1
    
    print(f"\nüéØ Resultado: {passed}/{total} pruebas pasaron")
    
    if passed == total:
        print("üéâ ¬°Todas las pruebas pasaron! El sistema est√° funcionando correctamente.")
        print("   ‚úÖ Backend funcionando")
        print("   ‚úÖ Modelo ML integrado")
        print("   ‚úÖ Endpoints respondiendo")
        print("   ‚úÖ Rendimiento aceptable")
    else:
        print("‚ö†Ô∏è  Algunas pruebas fallaron. Revisa los errores arriba.")
    
    print("\nüöÄ El sistema ToxiGuard con modelo ML est√° listo para usar!")
    print("\n" + "=" * 80)

if __name__ == "__main__":
    main()
