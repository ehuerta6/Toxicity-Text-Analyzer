"""
üß™ Script de prueba para el clasificador h√≠brido - ToxiGuard
Prueba la funcionalidad del clasificador h√≠brido y compara resultados
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app.hybrid_classifier import hybrid_classifier
from app.ml_classifier import ml_classifier
from app.improved_classifier import optimized_classifier

def test_classifiers():
    """Prueba todos los clasificadores con textos de ejemplo"""
    
    test_texts = [
        "Hello, how are you today?",
        "You are stupid and ugly",
        "I hate you, you should die",
        "This is a normal comment",
        "You are an idiot and I hope you suffer"
    ]
    
    print("üß™ PRUEBA DE CLASIFICADORES - TOXIGUARD")
    print("=" * 60)
    
    # Probar clasificador h√≠brido
    print("\nüî¨ CLASIFICADOR H√çBRIDO:")
    print("-" * 30)
    
    for i, text in enumerate(test_texts, 1):
        print(f"\nTexto {i}: {text}")
        result = hybrid_classifier.analyze_text(text)
        print(f"  ‚Ä¢ T√≥xico: {result['is_toxic']}")
        print(f"  ‚Ä¢ Porcentaje: {result['toxicity_percentage']}%")
        print(f"  ‚Ä¢ Nivel: {result['toxicity_level']}")
        print(f"  ‚Ä¢ Confianza: {result['confidence']}")
        print(f"  ‚Ä¢ Modelo: {result['model_used']}")
    
    # Probar clasificador ML
    print("\nü§ñ CLASIFICADOR ML (Linear SVM):")
    print("-" * 30)
    
    if ml_classifier.is_loaded:
        for i, text in enumerate(test_texts, 1):
            print(f"\nTexto {i}: {text}")
            result = ml_classifier.analyze_text(text)
            print(f"  ‚Ä¢ T√≥xico: {result['is_toxic']}")
            print(f"  ‚Ä¢ Porcentaje: {result['toxicity_percentage']}%")
            print(f"  ‚Ä¢ Nivel: {result['toxicity_level']}")
            print(f"  ‚Ä¢ Confianza: {result['confidence']}")
            print(f"  ‚Ä¢ Modelo: {result['model_used']}")
    else:
        print("‚ùå Clasificador ML no disponible")
    
    # Probar clasificador basado en reglas
    print("\nüìã CLASIFICADOR BASADO EN REGLAS:")
    print("-" * 30)
    
    for i, text in enumerate(test_texts, 1):
        print(f"\nTexto {i}: {text}")
        result = optimized_classifier.analyze_text(text)
        print(f"  ‚Ä¢ T√≥xico: {result['is_toxic']}")
        print(f"  ‚Ä¢ Porcentaje: {result['toxicity_percentage']}%")
        print(f"  ‚Ä¢ Nivel: {result['toxicity_level']}")
        print(f"  ‚Ä¢ Confianza: {result['confidence']}")
        print(f"  ‚Ä¢ Modelo: {result['model_used']}")
    
    # Informaci√≥n del clasificador h√≠brido
    print("\nüìä INFORMACI√ìN DEL CLASIFICADOR H√çBRIDO:")
    print("-" * 40)
    
    info = hybrid_classifier.get_classifier_info()
    print(f"Modo h√≠brido: {info['hybrid_mode']}")
    print(f"Clasificador ML disponible: {info['primary_classifier']['is_available']}")
    print(f"Clasificador de reglas disponible: {info['fallback_classifier']['is_available']}")
    
    if info['primary_classifier']['is_available']:
        performance = info['primary_classifier']['performance']
        print(f"Rendimiento ML:")
        print(f"  ‚Ä¢ F1-Score: {performance.get('f1_score', 'N/A')}")
        print(f"  ‚Ä¢ Precisi√≥n: {performance.get('precision', 'N/A')}")
        print(f"  ‚Ä¢ Recall: {performance.get('recall', 'N/A')}")
        print(f"  ‚Ä¢ Accuracy: {performance.get('accuracy', 'N/A')}")

def test_classifier_switching():
    """Prueba el cambio entre clasificadores"""
    
    print("\nüîÑ PRUEBA DE CAMBIO DE CLASIFICADORES:")
    print("-" * 40)
    
    # Cambiar a ML
    hybrid_classifier.set_primary_classifier(True)
    print("‚úÖ Cambiado a ML como principal")
    
    # Cambiar a reglas
    hybrid_classifier.set_primary_classifier(False)
    print("‚úÖ Cambiado a reglas como principal")
    
    # Volver a ML
    hybrid_classifier.set_primary_classifier(True)
    print("‚úÖ Vuelto a ML como principal")

if __name__ == "__main__":
    try:
        test_classifiers()
        test_classifier_switching()
        print("\n‚úÖ Todas las pruebas completadas exitosamente!")
        
    except Exception as e:
        print(f"\n‚ùå Error durante las pruebas: {e}")
        import traceback
        traceback.print_exc()
