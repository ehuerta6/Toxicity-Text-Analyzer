#!/usr/bin/env python3
"""
üß™ Test de Carga Autom√°tica ML - ToxiGuard
Verifica que los modelos ML se carguen autom√°ticamente
"""

import sys
import os

# Agregar el directorio del proyecto al path
sys.path.insert(0, str(os.path.dirname(__file__)))

def test_auto_loading():
    """Test de carga autom√°tica de modelos ML"""
    print("üîç Probando carga autom√°tica de modelos ML...")
    
    try:
        from app.ml_models import ml_classifier, hybrid_classifier
        
        print(f"‚úÖ ML Classifier:")
        print(f"   - Tipo: {ml_classifier.model_type}")
        print(f"   - Entrenado: {ml_classifier.is_trained}")
        print(f"   - Modelo: {type(ml_classifier.model).__name__}")
        
        print(f"\n‚úÖ Hybrid Classifier:")
        print(f"   - ML Entrenado: {hybrid_classifier.has_trained_ml_model()}")
        print(f"   - ML Modelo: {type(hybrid_classifier.ml_classifier.model).__name__}")
        
        return True
    except Exception as e:
        print(f"‚ùå Error: {e}")
        return False

def test_ml_prediction():
    """Test de predicci√≥n ML despu√©s de la carga autom√°tica"""
    print("\nüîç Probando predicci√≥n ML...")
    
    try:
        from app.ml_models import ml_classifier
        
        if ml_classifier.is_trained:
            print("üéØ Modelo ML est√° entrenado! Probando predicci√≥n...")
            
            # Test con diferentes textos
            test_texts = [
                "Hola mundo",
                "Eres un idiota est√∫pido",
                "La comida est√° deliciosa",
                "Te voy a matar"
            ]
            
            for text in test_texts:
                try:
                    is_toxic, prob, score = ml_classifier.predict_toxicity(text)
                    print(f"üìù '{text}' ‚Üí T√≥xico: {is_toxic}, Score: {score:.3f}")
                except Exception as e:
                    print(f"‚ùå Error prediciendo '{text}': {e}")
        else:
            print("‚ö†Ô∏è Modelo ML no est√° entrenado a√∫n")
            
        return True
    except Exception as e:
        print(f"‚ùå Error en test ML: {e}")
        return False

def test_hybrid_prediction():
    """Test de predicci√≥n h√≠brida"""
    print("\nüîç Probando predicci√≥n h√≠brida...")
    
    try:
        from app.ml_models import hybrid_classifier
        
        if hybrid_classifier.has_trained_ml_model():
            print("üéØ Clasificador h√≠brido con ML entrenado! Probando...")
            
            test_text = "Eres un idiota est√∫pido"
            result = hybrid_classifier.analyze_text(test_text)
            
            is_toxic, score, labels, text_length, word_count, category, toxicity_percentage = result
            
            print(f"üìù '{test_text}' ‚Üí Resultado h√≠brido:")
            print(f"   - T√≥xico: {is_toxic}")
            print(f"   - Score: {score:.3f}")
            print(f"   - Porcentaje: {toxicity_percentage}%")
            print(f"   - Categor√≠a: {category}")
            print(f"   - Etiquetas: {labels}")
        else:
            print("‚ö†Ô∏è Clasificador h√≠brido sin ML entrenado")
            
        return True
    except Exception as e:
        print(f"‚ùå Error en test h√≠brido: {e}")
        return False

def test_full_integration():
    """Test de integraci√≥n completa con services"""
    print("\nüîç Probando integraci√≥n completa...")
    
    try:
        from app.services import ToxicityClassifier
        classifier = ToxicityClassifier()
        
        print("‚úÖ ToxicityClassifier creado. Probando an√°lisis...")
        
        # Test con texto t√≥xico
        test_text = "Eres un idiota est√∫pido"
        result = classifier.analyze_text(test_text)
        
        is_toxic, score, labels, text_length, word_count, category, toxicity_percentage = result
        
        print(f"üìù '{test_text}' ‚Üí An√°lisis completo:")
        print(f"   - T√≥xico: {is_toxic}")
        print(f"   - Score: {score:.3f}")
        print(f"   - Porcentaje: {toxicity_percentage}%")
        print(f"   - Categor√≠a: {category}")
        print(f"   - Etiquetas: {labels}")
        
        # Determinar qu√© clasificador se us√≥
        if "ml_enhanced" in labels:
            classifier_used = "ML Model"
        elif "hybrid_ml" in labels:
            classifier_used = "Hybrid ML"
        elif "improved" in labels:
            classifier_used = "Improved Classifier"
        else:
            classifier_used = "Legacy Classifier"
            
        print(f"   - ü§ñ Clasificador usado: {classifier_used}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error en integraci√≥n: {e}")
        return False

def main():
    """Funci√≥n principal de testing"""
    print("üöÄ Iniciando test de carga autom√°tica ML...\n")
    
    tests = [
        test_auto_loading,
        test_ml_prediction,
        test_hybrid_prediction,
        test_full_integration
    ]
    
    passed = 0
    total = len(tests)
    
    for test in tests:
        try:
            if test():
                passed += 1
        except Exception as e:
            print(f"‚ùå Error ejecutando test: {e}")
    
    print(f"\nüìä Resultados: {passed}/{total} tests pasaron")
    
    if passed == total:
        print("üéâ Todos los tests pasaron! La integraci√≥n ML completa est√° funcionando.")
    else:
        print("‚ö†Ô∏è Algunos tests fallaron. Revisar errores arriba.")
    
    return passed == total

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
