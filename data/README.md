# Data - ToxiGuard

Esta carpeta estÃ¡ reservada para almacenar los datasets de entrenamiento, validaciÃ³n y pruebas para los modelos de Machine Learning.

## ğŸ¯ PropÃ³sito

La carpeta `data/` almacenarÃ¡:

- Datasets de entrenamiento para clasificaciÃ³n de toxicidad
- Datasets de validaciÃ³n y pruebas
- Datos preprocesados y limpios
- Scripts de limpieza y preparaciÃ³n de datos
- Metadatos y documentaciÃ³n de los datasets

## ğŸ“ Estructura futura

```
data/
â”œâ”€â”€ raw/                       # Datasets originales sin procesar
â”‚   â”œâ”€â”€ jigsaw_toxic_comments.csv    # Dataset principal de entrenamiento
â”‚   â””â”€â”€ additional_datasets/         # Otros datasets complementarios
â”œâ”€â”€ processed/                 # Datos limpios y preprocesados
â”‚   â”œâ”€â”€ train_processed.csv          # Datos de entrenamiento procesados
â”‚   â”œâ”€â”€ validation_processed.csv     # Datos de validaciÃ³n procesados
â”‚   â””â”€â”€ test_processed.csv           # Datos de prueba procesados
â”œâ”€â”€ scripts/                   # Scripts de procesamiento de datos
â”‚   â”œâ”€â”€ download_datasets.py         # Descarga automÃ¡tica de datasets
â”‚   â”œâ”€â”€ clean_data.py                # Limpieza y preprocesamiento
â”‚   â”œâ”€â”€ split_data.py                # DivisiÃ³n en train/validation/test
â”‚   â””â”€â”€ explore_data.py              # AnÃ¡lisis exploratorio de datos
â”œâ”€â”€ metadata/                  # InformaciÃ³n sobre los datasets
â”‚   â”œâ”€â”€ dataset_info.json            # DescripciÃ³n y estadÃ­sticas
â”‚   â”œâ”€â”€ schema.json                  # Estructura de columnas
â”‚   â””â”€â”€ version_control.md           # Control de versiones de datasets
â””â”€â”€ README.md                  # Este archivo
```

## ğŸ“Š Datasets principales

### Jigsaw Toxic Comments (Principal)

- **Fuente:** Kaggle - Jigsaw Unintended Bias in Toxicity Classification
- **TamaÃ±o:** ~2M comentarios
- **Columnas:** comment_text, toxic, severe_toxic, obscene, threat, insult, identity_hate
- **Idioma:** InglÃ©s
- **Uso:** Entrenamiento del modelo principal

### Datasets complementarios

- **Hate Speech Detection:** Comentarios de odio en redes sociales
- **Cyberbullying:** Acoso cibernÃ©tico y bullying online
- **Spam Detection:** Comentarios spam y no deseados

## ğŸ”§ Procesamiento de datos

### Limpieza bÃ¡sica

- EliminaciÃ³n de caracteres especiales y HTML
- NormalizaciÃ³n de espacios y puntuaciÃ³n
- ConversiÃ³n a minÃºsculas
- EliminaciÃ³n de URLs y menciones

### Preprocesamiento avanzado

- TokenizaciÃ³n y lematizaciÃ³n
- EliminaciÃ³n de stopwords
- NormalizaciÃ³n de texto
- Balanceo de clases (si es necesario)

### DivisiÃ³n de datos

- **Train:** 70% - Entrenamiento del modelo
- **Validation:** 15% - Ajuste de hiperparÃ¡metros
- **Test:** 15% - EvaluaciÃ³n final

## ğŸ“ˆ EstadÃ­sticas de datos

- **DistribuciÃ³n de clases:** Balance entre tÃ³xico/no tÃ³xico
- **Longitud de comentarios:** EstadÃ­sticas de longitud de texto
- **Vocabulario:** TamaÃ±o del vocabulario y palabras mÃ¡s frecuentes
- **Calidad:** Porcentaje de datos faltantes o corruptos

## ğŸ“‹ PrÃ³ximos pasos

1. Descargar dataset Jigsaw Toxic Comments
2. Implementar scripts de limpieza y preprocesamiento
3. Dividir datos en train/validation/test
4. Realizar anÃ¡lisis exploratorio de datos
5. Preparar datos para entrenamiento del modelo

## âš ï¸ Notas importantes

- Los datasets grandes no se incluirÃ¡n en el repositorio Git
- Usar `.gitignore` para excluir archivos de datos
- Mantener solo scripts y metadatos en el repositorio
- Documentar proceso de descarga y preparaciÃ³n de datos

---

_Reservado para datasets - Fase 2 del proyecto_
